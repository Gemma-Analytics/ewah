airflow:
  image:
    repository: gemmaanalytics/ewah
    tag: latest
    pullPolicy: Always
    pullSecret: ""

  executor: KubernetesExecutor
  fernetKey: "7T512UXSSmBOkpWimFHIVb8jK6lfmSAvx4mO6Arehnc="
  config:
    # EWAH
    AIRFLOW__CORE__FERNET_KEY: "7T512UXSSmBOkpWimFHIVb8jK6lfmSAvx4mO6Arehnc="
    # AIRFLOW__CORE__SQL_ALCHEMY_CONN: ""
    # EWAH_AIRFLOW_USER_SET: "False"
    AIRFLOW__WEBSERVER__AUTHENTICATE: "False"

    #K8s configs
    #AIRFLOW__KUBERNETES__WORKER_CONTAINER_REPOSITORY
    AIRFLOW__KUBERNETES__NAMESPACE: "ewah-dev"
    AIRFLOW__KUBERNETES__DAGS_IN_IMAGE: "True"


    # Security
    AIRFLOW__CORE__SECURE_MODE: "True"
    AIRFLOW__API__AUTH_BACKEND: "airflow.api.auth.backend.deny_all"
    AIRFLOW__WEBSERVER__EXPOSE_CONFIG: "False"
    AIRFLOW__WEBSERVER__RBAC: "False"

    # DAGS
    # AIRFLOW__CORE__LOAD_EXAMPLES: "False"

    ## Disable noisy "Handling signal: ttou" Gunicorn log messages
    GUNICORN_CMD_ARGS: "--log-level WARNING"

scheduler:

  ## custom airflow connections for the airflow scheduler
  ##
  connections:
    - id: my_aws
      type: aws
      extra: |
        {
          "aws_access_key_id": "XXXXXXXXXXXXXXXXXXX",
          "aws_secret_access_key": "XXXXXXXXXXXXXXX",
          "region_name":"eu-central-1"
        }
  ## custom airflow variables for the airflow scheduler
  ##
  variables: |
    { "environment": "dev" }
  ## custom airflow pools for the airflow scheduler
  ##
  pools: |
    {
      "example": {
        "description": "This is an example pool with 2 slots.",
        "slots": 2
      }
    }

web:
  ## configs for the Service of the web Pods
  ##
  service:
    type: NodePort

workers:
  ## the number of workers Pods to run
  ##
  replicas: 1

  #KE
  enabled: false

postgresql:
  enabled: true

flower:
#  #KE
  enabled: false

redis:
  #KE
  enabled: false
  #enabled: true
